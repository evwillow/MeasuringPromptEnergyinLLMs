{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Estimation Model for LLMs\n",
    "\n",
    "This notebook builds a robust predictive model to estimate energy consumption (Wh) based on prompt characteristics and API response metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for energy prediction modeling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "import joblib\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare energy consumption dataset\n",
    "df = pd.read_json('data/energy.jsonl', lines=True)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract comprehensive features from prompts and API responses\n",
    "def extract_prompt_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['prompt_length'] = df['prompt'].str.len()\n",
    "    df['prompt_word_count'] = df['prompt'].str.split().str.len()\n",
    "    df['prompt_sentence_count'] = df['prompt'].str.count(r'[.!?]+')\n",
    "    \n",
    "    df['prompt_uppercase_ratio'] = df['prompt'].str.count(r'[A-Z]') / df['prompt_length'].replace(0, 1)\n",
    "    df['prompt_digit_ratio'] = df['prompt'].str.count(r'[0-9]') / df['prompt_length'].replace(0, 1)\n",
    "    df['prompt_special_char_ratio'] = df['prompt'].str.count(r'[^a-zA-Z0-9\\s]') / df['prompt_length'].replace(0, 1)\n",
    "    df['prompt_question_marks'] = df['prompt'].str.count(r'\\?')\n",
    "    df['prompt_exclamation_marks'] = df['prompt'].str.count(r'\\!')\n",
    "    \n",
    "    df['is_english'] = df['prompt'].str.contains(r'^[a-zA-Z\\s\\d\\W]*$', regex=True).astype(int)\n",
    "    \n",
    "    df['response_length'] = df['response'].str.len()\n",
    "    df['response_word_count'] = df['response'].str.split().str.len()\n",
    "    \n",
    "    df['tokens_per_second'] = df['total_tokens'] / df['duration'].replace(0, 1)\n",
    "    df['energy_per_token'] = df['energy_consumed_wh'] / df['total_tokens'].replace(0, 1)\n",
    "    df['energy_per_word'] = df['energy_consumed_wh'] / df['prompt_word_count'].replace(0, 1)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    df['model_encoded'] = le.fit_transform(df['model'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = extract_prompt_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and clean dataset for modeling\n",
    "feature_columns = [\n",
    "    'prompt_length', 'prompt_word_count', 'prompt_sentence_count',\n",
    "    'prompt_uppercase_ratio', 'prompt_digit_ratio', 'prompt_special_char_ratio',\n",
    "    'prompt_question_marks', 'prompt_exclamation_marks', 'is_english',\n",
    "    'response_length', 'response_word_count',\n",
    "    'prompt_tokens', 'completion_tokens', 'total_tokens',\n",
    "    'duration', 'time_to_first_token', 'tokens_per_second',\n",
    "    'model_encoded'\n",
    "]\n",
    "\n",
    "df_clean = df[feature_columns + ['energy_consumed_wh']].dropna()\n",
    "df_clean = df_clean[df_clean['energy_consumed_wh'] > 0]\n",
    "\n",
    "X = df_clean[feature_columns]\n",
    "y = df_clean['energy_consumed_wh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data and scale features for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=df_clean['model_encoded']\n",
    ")\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models and evaluate performance\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=0.1),\n",
    "    'Elastic Net': ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=200, max_depth=20, min_samples_split=5, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, max_depth=6, random_state=42),\n",
    "    'Extra Trees': ExtraTreesRegressor(n_estimators=200, max_depth=20, min_samples_split=5, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name in ['Linear Regression', 'Ridge Regression', 'Lasso Regression', 'Elastic Net']:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "    \n",
    "    trained_models[name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model performance and select best model\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.sort_values('R2', ascending=False)\n",
    "\n",
    "best_model_name = results_df.index[0]\n",
    "best_model = trained_models[best_model_name]\n",
    "\n",
    "if best_model_name in ['Random Forest', 'Gradient Boosting', 'Extra Trees']:\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create energy prediction function and generate predictions\n",
    "def predict_energy(prompt_text, model_name, expected_tokens=50, expected_duration=1.0):\n",
    "    prompt_length = len(prompt_text)\n",
    "    prompt_word_count = len(prompt_text.split())\n",
    "    prompt_sentence_count = prompt_text.count('.') + prompt_text.count('!') + prompt_text.count('?')\n",
    "    prompt_uppercase_ratio = sum(1 for c in prompt_text if c.isupper()) / max(prompt_length, 1)\n",
    "    prompt_digit_ratio = sum(1 for c in prompt_text if c.isdigit()) / max(prompt_length, 1)\n",
    "    prompt_special_char_ratio = sum(1 for c in prompt_text if not c.isalnum() and not c.isspace()) / max(prompt_length, 1)\n",
    "    prompt_question_marks = prompt_text.count('?')\n",
    "    prompt_exclamation_marks = prompt_text.count('!')\n",
    "    is_english = 1 if prompt_text.isascii() else 0\n",
    "    \n",
    "    model_encoding = {\n",
    "        'gpt-4o-mini-2024-07-18': 0,\n",
    "        'llama-3.1-8b-instant': 1,\n",
    "        'mistral-large-latest': 2\n",
    "    }\n",
    "    \n",
    "    model_encoded = model_encoding.get(model_name, 0)\n",
    "    \n",
    "    features = np.array([\n",
    "        prompt_length, prompt_word_count, prompt_sentence_count,\n",
    "        prompt_uppercase_ratio, prompt_digit_ratio, prompt_special_char_ratio,\n",
    "        prompt_question_marks, prompt_exclamation_marks, is_english,\n",
    "        expected_tokens * 10,\n",
    "        expected_tokens * 2,\n",
    "        prompt_word_count * 1.3,\n",
    "        expected_tokens,\n",
    "        prompt_word_count * 1.3 + expected_tokens,\n",
    "        expected_duration,\n",
    "        expected_duration * 0.8,\n",
    "        (prompt_word_count * 1.3 + expected_tokens) / max(expected_duration, 0.1),\n",
    "        model_encoded\n",
    "    ]).reshape(1, -1)\n",
    "    \n",
    "    if best_model_name in ['Linear Regression', 'Ridge Regression', 'Lasso Regression', 'Elastic Net']:\n",
    "        features_scaled = scaler.transform(features)\n",
    "        prediction = best_model.predict(features_scaled)[0]\n",
    "    else:\n",
    "        prediction = best_model.predict(features)[0]\n",
    "    \n",
    "    return max(0, prediction)\n",
    "\n",
    "predictions = []\n",
    "for index, row in df.iterrows():\n",
    "    predicted_energy = predict_energy(row['prompt'], row['model'], row['total_tokens'], row['duration'])\n",
    "    \n",
    "    prediction_record = {\n",
    "        'prompt': row['prompt'],\n",
    "        'model': row['model'],\n",
    "        'timestamp': row['timestamp'],\n",
    "        'duration': row['duration'],\n",
    "        'time_to_first_token': row['time_to_first_token'],\n",
    "        'prompt_tokens': row['prompt_tokens'],\n",
    "        'completion_tokens': row['completion_tokens'],\n",
    "        'total_tokens': row['total_tokens'],\n",
    "        'tokens_per_second': row['tokens_per_second'],\n",
    "        'energy_consumed_wh': row['energy_consumed_wh'],\n",
    "        'predicted_energy_wh': round(predicted_energy, 6),\n",
    "        'response': row['response']\n",
    "    }\n",
    "    \n",
    "    predictions.append(prediction_record)\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.to_json('data/predictions.jsonl', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
